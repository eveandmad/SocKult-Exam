---
title: "SC script"
author: "Matilde"
date: "5/8/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---


```{r loading data}

pacman::p_load(tidyverse, 
               brms,
               bayesplot,
               viridis,#color pallette
               stringr,
               lme4,
               lmerTest, 
               rstatix,
               tidybayes,
               broom.mixed,
               wesanderson, #color pallette
               RColorBrewer, #color pallette
               ggsci, #color pallette
               arsenal, #comparedf
               openair #time average
)


#Loading data from google forms
part1 <- read_csv("Exam project spring 2020_part 1 (Responses) - Form Responses 1.csv")

part2 <- read_csv("Exam project spring 2020_part 2 (Responses) - Form Responses 1.csv")

p38 <- read_csv("Raw data/Completed participant IDs - clean.csv")

#Loading data from oTree
sc_round1 <- read_csv("sc_round1 (accessed 2020-05-14).csv") 
  
sc_round2 <- read_csv("sc_round2 (accessed 2020-05-14).csv")



```

## Template

### Data pre-processing
Cleaning data and getting it into the right format

```{r}

##Cleaning the google forms##
summary(part1)
##Part1
p1 <- part1 %>% 
  select("ID" = "Unique ID of own choice (important to remember for part 2)",
         "URL" = "Step 3: Paste the unique URL link below")

#Getting URL code from web-link
p1$URL <- str_remove(p1$URL, "https://socialcognition.au.dk/p/") 
p1$URL <- str_remove_all(p1$URL, '[:punct:].*') 

##Part 2##
summary(part2)
p2 <- part2 %>% 
  select("ID" = "Self-chosen ID (the same as the one used for the first part)",
         "URL" = "Step 3: Paste the unique URL link below")
#Getting URL code from web-link
p2$URL <- str_remove(p2$URL, "https://socialcognition.au.dk/p/") 
p2$URL <- str_remove_all(p2$URL, '[:punct:].*') 

#renaming
p38$`URL round 2` <- gsub("8gnlaox0", "8gnloax0", p38$`URL round 2`)

##Cleaning oTree data##
##Round 1
summary(sc_round1)
sc1 <- sc_round1 %>% 
  select("ParticipantN" = "participant.id_in_session",
         "URL round 1" = "participant.code",
         "Round" = "participant._current_app_name",
         "FirstRating" = "player.rating1",
         "GroupRating" = "player.TPrating",
         "FaceID" = "player.faceid",
         "TimeStamp1" = "participant.time_started")
sc1 <- na.omit(sc1)

##Round 2

sc2 <- sc_round2 %>% 
  select("ParticipantN" = "participant.id_in_session",
         "URL round 2" = "participant.code",
         "Round" = "participant._current_app_name",
         "SecondRating" = "player.rating2",
         "FaceID" = "player.faceid",
         "TimeStamp2" = "participant.time_started") 
sc2 <- na.omit(sc2)

#Binding columns for systematically matched data
d1 <- merge(p1, sc1, by = "URL")
d2 <- merge(p2, sc2, by = "URL")
d <- merge(d1, d2, by = c("FaceID","ID"))
#counting ID's
dID <- as.data.frame(unique(d$ID))
count(dID)

#For manually cleaned data
d381 <- merge(p38, sc1, by = "URL round 1")
d382 <- merge(p38, sc2, by = "URL round 2")
d38 <- merge(d381, d382, by = c("FaceID","ID"))

#counting ID's
d38ID <- as.data.frame(unique(d38$ID))
count(d38ID)

#Getting time stamp
last_round1 <- d38[ !duplicated(d38$ID,fromLast=TRUE), ]
first_round1 <- d38[ !duplicated(d38$ID), ]
time <- merge(last_round1, first_round1, by ="ID")
time$time_dif <- time$TimeStamp2.y - time$TimeStamp1.y
time %>% as.numeric(time$time_dif) 
time$hours <- time$time_dif/60
mean(time$hours)
sd(time$hours)

#Creating Feedback for systematically matched data
d$Feedback <- d$GroupRating - d$FirstRating
d <- d %>%
  mutate(
    Feedback = ifelse(GroupRating==0, NA, Feedback)
  )

#Creating feedback for manually matched data
d38$Feedback <- d38$GroupRating - d38$FirstRating
d38 <- d38 %>%
  mutate(
    Feedback = ifelse(GroupRating==0, NA, Feedback)
  )

#Creating raw change scores
#systematic match
d$Change <- d$SecondRating - d$FirstRating
#manual match
d38$Change <- d38$SecondRating - d38$FirstRating


##Checking for regression to the mean in manually matched data
d38_2 <- subset(d38, is.na(Feedback))
d38_2ID <- as.data.frame(unique(d38_2$ID))
count(d38_2ID)

#What is the tendency to shrink values when there is no feedback 
m <- lmer(SecondRating ~ 1 + FirstRating + (1  | ID), 
          subset(d38, is.na(Feedback)), REML=F)
summary(m)

#Estimate of a correlation between first and second rating. 1 = perfectly correlated, the smaller it is the more regression to the mean
ggplot(subset(d38, is.na(Feedback)), aes(FirstRating,SecondRating)) + 
  geom_point() +
  geom_smooth(method=lm)

d38$Changeabs <- abs(d38$Change)
mean(d38$Changeabs)

#Randomizing subject ID

dID <- as.data.frame(unique(d$ParticipantN.x))
count(dID)

#Write csv
write.csv(d38, file = "d38.csv")
```


Exploring by group rating: manually matched data

```{r}
#Reading cleaned data
d38 <- read.csv("d38.csv")

#Creating different subsets for different types of feedback and new column for for 3 levels of feedback
d38low <- subset(d38, Feedback %in% c(-3,-2))
d38low$Feedback2 <- -2.5
d38same <- subset(d38, Feedback %in% c(-1, 0, 1))
d38same$Feedback2 <- 0
d38high <- subset(d38, Feedback %in% c(3,2))
d38high$Feedback2 <- 2.5


#Summary statistics of first and second rating for different types of feedback
d38 %>% 
  get_summary_stats(FirstRating,type = "mean_sd")
d38 %>% 
  get_summary_stats(SecondRating,type = "mean_sd")

#Summary statistics of change for different types of feedback
d38low %>% 
  get_summary_stats(Change,type = "mean_sd")
d38same %>% 
  get_summary_stats(Change,type = "mean_sd")
d38high %>% 
  get_summary_stats(Change,type = "mean_sd")

#Creating subset with only low and high feedback and selecting relevant columns
d38_lh <- rbind(d38low,d38high)

d38_lh <- d38_lh %>% select(
  "FaceID",
  "ID",
  "Participant" = "ParticipantN.x",
  "FirstRating",
  "GroupRating",
  "SecondRating",
  "Feedback",
  "Change"
)

#Combined with new Feedback column
d38_lsh <- rbind(d38low,d38same,d38high)
d38_lsh <- d38_lsh %>% select(
  "FaceID",
  "ID",
  "Participant" = "ParticipantN.x",
  "FirstRating",
  "GroupRating",
  "SecondRating",
  "Feedback",
  "Change",
  "Feedback2"
)
```

Exploring by group rating: systematically matched data
```{r}
#Systematically paired
dlow <- subset(d, Feedback %in% c(-3,-2))
dlow$Feedback2 <- -2.5
dsame <- subset(d, Feedback %in% c(-1, 0, 1))
dsame$Feedback2 <- 0
dhigh <- subset(d, Feedback %in% c(3,2))
dhigh$Feedback2 <- 2.5

#Creating subset with only low and high feedback and selecting relevant columns
d_lsh <- rbind(dlow,dsame,dhigh)

d_lsh <- d_lsh %>% select(
  "FaceID",
  "ID",
  "Participant" = "ParticipantN.x",
  "FirstRating",
  "GroupRating",
  "SecondRating",
  "Feedback",
  "Change",
  "Feedback2"
)

```


Combining data from Simonsen et al. 2019, Unpublished in-class study 2020 & Unpublished own study 2020
```{r}
#Rading cleaned data-sets
simonsen <- read_csv("Simonsen_clean.csv")
sc <- read_csv("sc_clean.csv")
cogsci <- read_csv("cogsci_clean.csv")

#Combining them into one dataframe
all_d <- rbind(simonsen, sc, cogsci)

#Counting ID's
alldID <- as.data.frame(unique(all_d$ID))
count(alldID)

#Creating feedback divided by type
allLow <- subset(all_d, Feedback %in% c(-3,-2))
allLow$Feedback2 <- -2.5
allSame <- subset(all_d, Feedback %in% c(-1, 0, 1))
allSame$Feedback2 <- 0
allHigh <- subset(all_d, Feedback %in% c(3,2))
allHigh$Feedback2 <- 2.5

all_d <- rbind(allLow,allSame,allHigh)

```



### Define your hypotheses
People will conform to peer feedback, that is, they will change according to the feedback (effect > 0.17)

### Describe variables
Outcome: 
- Change (amount of change from the first rating)
Predictors: 
- Feedback (difference between first rating and peer feedback)
- FirstRating (starting point, e.g. if early rating is 8, difficult to go up!)
Varying effects:
- ID: participant ID
- FaceID: stimulus ID

### Identify your model[s] 
* likelihood function: Change is numeric and goes from -6 to +6. Roughly gaussian?
* formula: Change ~ 1 + FirstRating + Feedback + 
                         (1 + FirstRating + Feedback | ID) + 
                         (1 + FirstRating + Feedback | FaceID))
* priors

```{r}
#Model for own data only : Low and High feedback type
SocConformity_f1 <- bf(Change ~ 1 + FirstRating + Feedback + 
                         (1 + FirstRating + Feedback | Participant) + 
                         (1 + FirstRating + Feedback | FaceID))

get_prior(SocConformity_f1, d38_lh, family = gaussian)

SocConformity_prior <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, .3), class = b),
  prior(normal(0, .3), class = sd),
  prior(lkj(5), class = cor),
  prior(normal(0,1), class = sigma)
)

SocConformity_m_prior <- brm(
  SocConformity_f1,
  d38_lh,
  family = gaussian,
  prior = SocConformity_prior,
  sample_prior = "only",
  chains = 2,
  cores = 2,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  )
)

prior_check <- pp_check(SocConformity_m_prior, nsamples=100)

(prior_check
  +ggtitle("Prior predictive check"))

```

## Fit the model and assess model quality

```{r}
SocConformity_m <- brm(
  SocConformity_f1,
  d38_lh,
  family = gaussian,
  prior = SocConformity_prior,
  sample_prior = T,
  chains = 4,
  cores = 2,
  iter = 4000,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  )
)

summary(SocConformity_m)

post_check <- pp_check(SocConformity_m, nsamples=100)
(post_check
  +ggtitle("Posterior predictive check"))

#Assessing chains
#Traceplot
color_scheme_set("viridis")
mcmc_trace(SocConformity_m,
           pars = c("b_Intercept", "b_Feedback", 
           "sd_FaceID__Intercept", "sd_FaceID__Feedback",
           "sd_Participant__Intercept", "sd_Participant__Feedback")) + 
  theme_classic()

SocConformity_m %>% plot(combo = c("hist", "trace"), theme = theme_bw(base_size = 18), main = "Posterior distribution and trace plots" )
#Overlay
mcmc_rank_overlay(SocConformity_m,
                  pars = c("b_Intercept", "b_Feedback", 
           "sd_FaceID__Intercept", "sd_FaceID__Feedback",
           "sd_Participant__Intercept", "sd_Participant__Feedback")) + theme_classic()

# The posteriors have moved or gotten more confident than the priors
plot(hypothesis(SocConformity_m,"Intercept > 0"))
plot(hypothesis(SocConformity_m,"Intercept > 0", class="sd", group="FaceID"))
plot(hypothesis(SocConformity_m,"Intercept > 0", class="sd", group="Participant"))
plot(hypothesis(SocConformity_m,"Feedback > 0"))
plot(hypothesis(SocConformity_m,"Feedback > 0", class="sd", group="FaceID"))
plot(hypothesis(SocConformity_m,"Feedback > 0", class="sd", group="Participant"))
plot(conditional_effects(SocConformity_m), points=T, rug=T)[[1]] + theme_classic()

```

## Results and hyp testing
```{r}
summary(SocConformity_m)

tab_model(SocConformity_m)
#hypothesis 1: there is an effect of social conformity
hypothesis(SocConformity_m,"Feedback > 0")

## Visualize 
conditional_effects(SocConformity_m)

estimates <- ranef(SocConformity_m)

xx <- predict(SocConformity_m, summary=T)

d38_lh <- cbind(d38_lh,xx)
d38_lh$Participant <- as.factor(d38_lh$Participant)
ggplot(d38_lh) + 
  geom_point(aes(Feedback,Change, color = ID, group=ID), show.legend=F) + 
  geom_smooth(method=lm, se=F, aes(Feedback,Change, color = ID), show.legend=F) +
  ggtitle("Regression of change on participant level")


X <- hypothesis(SocConformity_m, "Feedback > 0", group = "Participant", scope = "coef")
X$hypothesis %>%
  left_join(distinct(d38_lh, Group = Participant)) %>% 
  mutate(Participant = factor(Group), Conformity = Estimate) %>%
  ggplot(aes(Conformity, Participant)) +
  geom_errorbarh(aes(xmin = CI.Lower, xmax = CI.Upper)) +
  geom_point() + theme_classic() + 
  ggtitle("Effect of feedback on participant level", subtitle="Social conformity estimates with 95%CI")

```

Models indexed by group opinion
```{r}
SocConformity_low <- update(SocConformity_m, formula = SocConformity_f1, newdata = d38low)
SocConformity_same <- update(SocConformity_m, formula = SocConformity_f1, newdata = d38same)
SocConformity_high <- update(SocConformity_m, formula = SocConformity_f1, newdata = d38high)

summary(SocConformity_low)
summary(SocConformity_same)
summary(SocConformity_high)
```

Model systematically merged data
```{r}
m_d <- update(SocConformity_m, formula = SocConformity_f1, newdata = d_lh)

summary(m_d)

#Participant level
xxd <- predict(m_d, summary=T)
d <- cbind(d,xxd)
d$ID <- as.factor(d$ID)
ggplot(d) + 
  geom_point(aes(Feedback,Change, color = ID, group=ID))+#, show.legend=F) 
  geom_smooth(method=lm, se=F, aes(Feedback,Change, color = ID))+#, show.legend=F) 
  ggtitle("Regression of change on participant level")

#violin boxplot by condition
d_lsh$Feedback2 <- as.factor(d_lsh$Feedback2)

#3 levels of feedback
ggplot(d_lsh, aes(x=Feedback2, y=Change, color=Feedback2)) +
    geom_jitter(color="grey", size=0.2, alpha=0.2, na.rm = T) +
    geom_violin(position="dodge", width=1, fill="transparent") +
    geom_boxplot(width=0.3, alpha=.5, fill = "black") +
    scale_color_manual(values = wes_palette("GrandBudapest1", n = 3))+
    theme_classic() +
    theme(
      legend.position="bottom",
      plot.title = element_text(size=11)
    ) +
    ggtitle(expression(bold("Change in trustworthiness according to feedback")), subtitle = "Grouped by condition") +
    xlab("Feedback type")

```

Comparing systematic and manually matched data
```{r}
d38_lsh$match <- "manual"
d_lsh$match <- "systrmatic"

d_ms <- rbind(d38_lsh, d_lsh)

#violin boxplot by condition
d_ms$Feedback2 <- as.factor(d_ms$Feedback2)

#3 levels of feedback
ggplot(d_ms, aes(x=Feedback2, y=Change, color=Feedback2)) +
    geom_jitter(color="grey", size=0.2, alpha=0.2, na.rm = T) +
    geom_violin(position="dodge", width=1, fill="transparent") +
    geom_boxplot(width=0.3, alpha=.5, fill = "black") +
    scale_color_manual(values = wes_palette("GrandBudapest1", n = 3))+
    theme_classic() +
    theme(
      legend.position="bottom",
      plot.title = element_text(size=11)
    ) +
    ggtitle(expression(bold("Change in trustworthiness according to feedback")), subtitle = "Grouped by condition") +
    xlab("Feedback type")+
    facet_wrap(~match)

```


Model with condition
```{r}
Combined_f1 <- bf(Change ~ 0 + FirstRating:Condition + Feedback:Condition + 
                         (1 + FirstRating + Feedback | ID) + 
                         (1 + FirstRating + Feedback | FaceID))

get_prior(Combined_f1, all_d, family = gaussian)

Combined_prior <- c(
  prior(normal(0, .3), class = b, coef = ConditionPeri:Feedback),
  prior(normal(0, .3), class = b, coef = ConditionPre:Feedback),
  prior(normal(0, .5), class = b, coef = FirstRating:ConditionPeri),
  prior(normal(0, .5), class = b, coef = FirstRating:ConditionPre),
  prior(normal(0, .3), class = sd),
  prior(lkj(5), class = cor),
  prior(normal(0,1), class = sigma)
)

#Combined_m1 <- update(SocConformity_m, formula = Combined_f1, newdata = all_d)

#Prior check
Combined_m_prior <- brm(
  Combined_f1,
  all_d,
  family = gaussian,
  prior = Combined_prior,
  sample_prior = "only",
  chains = 2,
  cores = 2,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  )
)

prior_check <- pp_check(Combined_m_prior, nsamples=100)
(prior_check
  +ggtitle("Prior predictive check"))

#Posterior
Combined_m <- brm(
  Combined_f1,
  all_d,
  family = gaussian,
  prior = Combined_prior,
  sample_prior = T,
  chains = 4,
  cores = 2,
  iter = 4000,
  control = list(
    adapt_delta = 0.99,
    max_treedepth = 20
  )
)

post_check <- pp_check(Combined_m, nsamples=100)
(post_check
  +ggtitle("Posterior predictive check"))

```

## Results and hyp testing
```{r}
Combined_m %>% plot(combo = c("hist", "trace"), theme = theme_bw(base_size = 18), main = "Posterior distribution and trace plots" )
#Overlay
mcmc_rank_overlay(Combined_m,
                  pars = c("b_FirstRating:ConditionPeri", "b_FirstRating:ConditionPre", 
                           "b_ConditionPeri:Feedback","b_ConditionPre:Feedback",
                            "sd_FaceID__FirstRating", "sd_FaceID__Feedback",
                            "sd_ID__Feedback", "sd_ID__FirstRating")) + theme_classic()

summary(Combined_m)
posterior_summary(Combined_m, pars = c("^b_", "^sd_"), probs = c(0.025, 0.975) )
#hypothesis 1: there is an effect of social conformity
hypothesis(Combined_m,"ConditionPeri:Feedback > ConditionPre:Feedback")
hypothesis(Combined_m,"ConditionPre:Feedback > ConditionPeri:Feedback")
hypothesis(Combined_m,"ConditionPeri:Feedback > 0")
hypothesis(Combined_m,"ConditionPre:Feedback > 0")

p1 <- plot(hypothesis(Combined_m,"ConditionPeri:Feedback > 0"))
p1 + ggtitle("Evidence for effect of feedback")

plot(hypothesis(Combined_m1,"ConditionPre:Feedback > 0"))

## Visualize 
conditional_effects(Combined_m)

estimates <- ranef(Combined_m)

#Participant level
xx1 <- predict(Combined_m, summary=T)
all_d <- cbind(all_d,xx1)
all_d$ID <- as.factor(all_d$ID)
ggplot(all_d) + 
  geom_point(aes(Feedback,Change, color = ID, group=ID))+#, show.legend=F) 
  geom_smooth(method=lm, se=F, aes(Feedback,Change, color = ID))+#, show.legend=F) 
  ggtitle("Regression of change on participant level")

#violin boxplot by condition
all_d$Feedback2 <- as.factor(all_d$Feedback2)

#3 levels of feedback
ggplot(all_d, aes(x=Feedback2, y=Change, color=Feedback2)) +
    geom_jitter(color="grey", size=0.2, alpha=0.2, na.rm = T) +
    geom_violin(position="dodge", width=1, fill="transparent") +
    geom_boxplot(width=0.3, alpha=.5, fill = "black") +
    scale_color_manual(values = wes_palette("GrandBudapest1", n = 3))+
    theme_classic() +
    theme(
      legend.position="bottom",
      plot.title = element_text(size=11)
    ) +
    ggtitle(expression(bold("Change in trustworthiness according to feedback")), subtitle = "Grouped by condition") +
    xlab("Feedback type")+
    facet_wrap(~Condition)
#5 levels of feedback
ggplot(all_d, aes(x=Feedback, y=Change, color=Feedback)) +
    geom_jitter(color="grey", size=0.2, alpha=0.2, na.rm = T) +
    geom_violin(position="dodge", width=0.8, fill="transparent") +
    geom_boxplot(width=0.3, alpha=.5, fill = "black") +
    #scale_color_viridis(discrete = T, option="magma") + 
    scale_color_manual(values = wes_palette("Darjeeling1", n = 5))+
    theme_classic()+
    theme(
      legend.position="bottom",
      plot.title = element_text(size=11)
    ) +
    ggtitle(expression(bold("Change in trustworthiness according to feedback")), subtitle = "Grouped by condition") +
    xlab("Feedback type")+
  facet_wrap(~Condition)


```


### Report

### Methods and Materials
#### Participants

#### Experimental setup
In order to investigate whether implicit social conformity can be found beyond regression to the mean, we relied on the XNXN paradigm. DESCRIPTION OF THE PARADIGM.

#### Statistical analysis
The underlying causal diagram was formalized using Directed Acyclical Graphs in Figure XX. The diagram indicates the necessity to control for BLABLA in order to avoid BLABLA.
In order to confirm the adequacy of such approach we set up a simulation of the data generating process and compared N statistical models in their ability to infer the true parameters.
The simulation involved BLABLA
The results indicated that the model including BLABLA could indeed recover the true parameter with high precision. See plot/table.
We therefore constructed two models on the actual data from the experiment, in order to assess whether Feedback had an effect on the second rating.
As outcome we chose Change (between own ratings) modeled relying on a Gaussian likelihood. In the first model we only used First Rating as a predictor, in the second we added Feedback. Both models had a full varying structure of the predictors, varying both by Participant and by Face stimulus.
As priors we chose blabla and checked with prior predictive checks whether the scale of the expected outcomes was correct (e.g. avoiding impossible change values, such as + 100). See figure S1.
We tested for model quality in terms of no divergences, Rhat < 1.05, effective samples above 200, posterior predictive checks, visual inspection of the markov chains (raw and ranked) and assessment as to whether the posterior had learned from the data (contrast with prior). Model quality was ensured, details are reported in the appendix.
We compared the two models using loo based stacking weights model comparison (REF).
If the model including feedback was reliably better than the model without feedback, we would then more specifically test our hypothesis of implicit conformity relying on evidence ratio, that is, the amount of posterior samples compatible with our hypothesis divided the amount of incompatible posterior samples.
The modeling was performed relying on R 4.0.0, RStudio blalb, tidyverse, brms, Stan (REFS)

### Results

Model comparison revealed that no model was clearly better than the other, suggesting caution when testing hypotheses on our theoretically motivated model, which includes Feedback.
As expected we saw a credible positive effect of feedback on the change in rating beyond regression to the mean (B = 0.02, SE= 0.01, 95% CIs blabla, ER = 27.). See figure blabla. 
The effect was small, but quite consistent across participants, see figure blabla.
For full details on the model see Table S1.
